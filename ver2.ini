import cv2
import numpy as np

def process_video(video_path):
    # 비디오 캡처 초기화
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print("Error: Could not open video.")
        return

    # Background Subtractor 객체 생성 (KNN 사용)
    fgbg = cv2.createBackgroundSubtractorKNN(history=500, dist2Threshold=400.0, detectShadows=False)

    # 사람 인식 모델 초기화 (모바일넷 SSD 사용)
    net = cv2.dnn.readNetFromCaffe(
        'deploy.prototxt',
        'res10_300x300_ssd_iter_140000_fp16.caffemodel'
    )

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # 배경 차별화 적용
        fgmask = fgbg.apply(frame)
        
        # 사람 인식을 위해 프레임 준비
        (h, w) = frame.shape[:2]
        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)
        net.setInput(blob)
        detections = net.forward()

        # 사람 인식된 영역 마스크 생성
        person_mask = np.zeros_like(fgmask)
        for i in range(detections.shape[2]):
            confidence = detections[0, 0, i, 2]
            if confidence > 0.5:  # 인식 신뢰도 임계값 조정
                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
                (startX, startY, endX, endY) = box.astype("int")
                cv2.rectangle(person_mask, (startX, startY), (endX, endY), 255, -1)
        
        # 마스크 후처리 (경계 선명하게 하기)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)
        
        # 사람 영역을 배경 업데이트에서 제외
        fgmask[person_mask == 255] = 0
        
        # 마스크 후처리 (경계 선명하게 하기)
        fgmask = cv2.dilate(fgmask, kernel, iterations=2)
        fgmask = cv2.erode(fgmask, kernel, iterations=2)
        
        # 교수님 영역만 추출하여 배경으로 대체
        fgmask_inv = cv2.bitwise_not(fgmask)
        fg = cv2.bitwise_and(frame, frame, mask=fgmask_inv)
        
        # 실시간 배경 업데이트
        bg_frame = fgbg.getBackgroundImage()
        if bg_frame is not None:
            bg_part = cv2.bitwise_and(bg_frame, bg_frame, mask=fgmask)
            combined = cv2.add(fg, bg_part)
        else:
            combined = fg
        
        # 결과 프레임 출력
        cv2.imshow('Frame', combined)
        
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# 사용자에게 동영상 파일 경로 입력 받기
video_path = input("동영상 파일 경로를 입력하세요: ").strip()
process_video(video_path)
